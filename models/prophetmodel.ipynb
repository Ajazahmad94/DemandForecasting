{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05879227",
   "metadata": {},
   "source": [
    "# `fb-Prophet` Machine Learning Model Documentation\n",
    "\n",
    "\n",
    "**`fbprophet`** in this notebook we are implementing the fb prophet Model\n",
    "\n",
    "## Key Parameters\n",
    "        \n",
    "- **Growth Detection:** Detecting growth using custom method Ex: linear or Logistic  \n",
    "\n",
    "- **Automatic Changepoint Detection:** Using Pelt algo to detect changepoints.\n",
    "\n",
    "- **Generating Ramadan Days:** Using a Hijri Converter fn to generate Ramadan Days between two years\n",
    "\n",
    "- **Seasonality Modeling:** Experimenting various types of seasonality, such as yearly, weekly, and daily patterns and Ramadan.\n",
    "\n",
    "- **Holidays and Special Events:** Adding Ramadan as a special Holiday to include the Ramadan effect.\n",
    "\n",
    "- **Additional Regressors:** \n",
    "- **Multiplicative Seasonality:** specify custom trend components\n",
    "- **Outliers:** Using traditional stat method \n",
    "- **Cross Validation:** \n",
    "- **Hyperparameter tuning:** \n",
    "- **Generate future dates:** \n",
    "\n",
    "\n",
    "### Installation Usage: Install the required dependencies:\n",
    "To use `fbprophet`, you need following libraries.\n",
    "- pip install Prophet\n",
    "- pip install pelt\n",
    "- pip install ruptures\n",
    "- pip install math\n",
    "- pip install holidays\n",
    "- pip install hijri_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520cc1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import myModule as myModule\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037303e7",
   "metadata": {},
   "source": [
    "# Imported data using LoadData function from myModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55a79f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'myModule' has no attribute 'fileIO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ajaz/DemandForecasting/Data/sampledata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39mmyModule\u001b[38;5;241m.\u001b[39mfileIO\u001b[38;5;241m.\u001b[39mloadCsvExcelFile(file_path)\n\u001b[1;32m      3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'myModule' has no attribute 'fileIO'"
     ]
    }
   ],
   "source": [
    "file_path =\"/home/ajaz/DemandForecasting/Data/sampledata.csv\"\n",
    "data =myModule.fileIO.loadCsvExcelFile(file_path)\n",
    "data['ds'] = pd.to_datetime(data['date'])\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45687d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #Now you can use the functions like this:\n",
    "myModule.fileIO.loadCsvExcelFile(file_path)\n",
    "myModule.dataAnalysis.detectGrowth(data)\n",
    "myModule.dateGeneration.generateRamadanDates(year)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfa77f",
   "metadata": {},
   "source": [
    "# **Parameters**\n",
    "### ******Input Parameters from Interface******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda05864",
   "metadata": {},
   "source": [
    "### *****Model Parameters: Parameters passed inside the model itself Directly*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45565b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Growth mode: 'linear', 'logistic',  'flat', None (determined by user or method)\n",
    "\n",
    "growth=None # if this is none then growth will be determined by the user else it will be determined by our method if determineGrowth is true\n",
    "determineGrowth=True # If True, growth is determined by our method; else, by the user\n",
    "\n",
    "#If ,mc_samples=0 then MAP estimation is used\n",
    "mcmc_samples =None # Number of samples for MCMC (Markov Chain Monte Carlo)\n",
    "\n",
    "#Interval_width: Sets the width of the uncertainty intervals provided in the forecast. A larger `interval_width` (e.g., 0.95) provides wider intervals, reflecting increased uncertainty.\n",
    "interval_width =None # Uncertainty in the trend\n",
    "\n",
    "#Seasonality mode: 'multiplicative' or 'additive'\n",
    "#seasonality_mode is proportional to the baseline, allowing for variations in magnitude with changes in the overall level of the time series.\n",
    "#Can detect with seasonality_mode='multiplicative' or 'additive' with Growth function as 'linear' or 'logistic', Linear will be additive and logistic will be multiplicative:Need experimentation\n",
    "\n",
    "seasonality_mode='multiplicative'\n",
    "\n",
    "#We are using inbuilt option and weekends are not included in this, but later we might use custom holidays\n",
    "customholidays_df = pd.DataFrame({'ds': [], 'holiday': []})\n",
    "holidays_prior_scale =None       #  parameter that determines the degree to which the holiday components are allowed to impact the forecast. If this is set to zero, then the holiday effects are not used. Increasing it will allow the holidays to have more effect. Default is 10, which provides very little regularization. Low Value: 0.05 , High Value : 10 or higher\n",
    "\n",
    "# Yearly, Monthly,Ramadan,Weekend days seasonality\n",
    "yearly_seasonality=False # Default is 20\n",
    "weekly_seasonality=False\n",
    "daily_seasonality=False\n",
    "\n",
    "#changepoints\n",
    "#changepoints: Pelt is generating better results\n",
    "changepoint_prior_scale  =None     #How flexible the changepoints are allowed to be, high it will be more flexible, can lead to overfitting also (ex: 10,30)\n",
    "n_changepoints =None               #This effects the results. Pelt is handling better\n",
    "changepoint_range =None            #By default its good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671d520",
   "metadata": {},
   "source": [
    "#### ******Parameters as a custom Parameters: Ex: Additional Seasonality******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional  Seasonality regressors\n",
    "\n",
    "#Custom holidays\n",
    "country_name='SA' # Country Code  (ISO 3166-2) for holidayss\n",
    "\n",
    "\n",
    "yearly_add_seasonality=False\n",
    "yearly_season_period=None\n",
    "yearly_season_fourier_order=None\n",
    "\n",
    "quarterly_add_seasonality=False\n",
    "quarterly_season_period=None\n",
    "quarterly_season_fourier_order=None\n",
    "\n",
    "monthly_add_seasonality=False\n",
    "monthly_season_period=None\n",
    "monthly_season_fourier_order=None\n",
    "\n",
    "# Weekend days (0-6, Mon-Sun)\n",
    "weekend_days = [4]  # 4 is Friday\n",
    "\n",
    "Weekend_add_seasonality=False\n",
    "weekendDaysCount=1\n",
    "Weekends_fourier_order=15\n",
    "\n",
    "WorkingDays_add_seasonality=False\n",
    "workingDaysCount=6\n",
    "WorkingDays_fourier_order=5\n",
    "\n",
    "ramadan_add_seasonality=True\n",
    "ramadan_period=29.33\n",
    "ramadan_fourier_order=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412df83",
   "metadata": {},
   "source": [
    "#### ******Parameters used in other calc, other than the model******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty sensitivity for PELT algorithm: 'High', 'Medium', 'Low' : Used to determine the penalty value for the PELT algo which is used for changepoint detection\n",
    "PenaltySensitivity =\"High\"  \n",
    "\n",
    "# Model type for changepoint detection: 'l1' (linear 1), 'l2' (linear 2), 'rbf' (radial basis function)\n",
    "pltModelType = \"l2\"  # \"l2\", \"rbf\"\n",
    "\n",
    "\n",
    "detectoutliers =False # If True, outliers are detected and removed from the data else outliers are not detected and not removed from the data\n",
    "\n",
    "#IQR stands for Interquartile Range, which is a measure of statistical dispersion of data\n",
    "#IQR Range for outlier detection (1.5 is default) 3 is too high ,  upper_bound = Q3 + IQRRange * IQR and lower_bound = Q1 - IQRRange * IQR \n",
    "\n",
    "IQRRange=1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5bf95",
   "metadata": {},
   "source": [
    "# ****Prophet Algorithm****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebf7ee",
   "metadata": {},
   "source": [
    "#### ******Input Parameters Processed and Passed inside the Model directly******\n",
    "#### ****Processing Parameters****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Prophet model with flexible parameters\n",
    "prophet_params = {\n",
    "    'growth': growth if determineGrowth else None,\n",
    "    'mcmc_samples': mcmc_samples,\n",
    "    'interval_width': interval_width,\n",
    "    'seasonality_mode': seasonality_mode,\n",
    "    'custom_holidays': customholidays_df if not customholidays_df.empty else None,\n",
    "    'holidays_prior_scale': holidays_prior_scale,\n",
    "    'yearly_seasonality': yearly_seasonality,\n",
    "    'weekly_seasonality': weekly_seasonality,\n",
    "    'daily_seasonality': daily_seasonality,\n",
    "    'changepoint_prior_scale': changepoint_prior_scale,\n",
    "    'n_changepoints': n_changepoints,\n",
    "    'changepoint_range': changepoint_range,\n",
    "}\n",
    "print(prophet_params)\n",
    "# Remove parameters with value None\n",
    "prophet_params = {key: value for key, value in prophet_params.items() if value is not None}\n",
    "print(prophet_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c065b3",
   "metadata": {},
   "source": [
    "### ****Importing Libraries****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import math\n",
    "import ruptures as rpt\n",
    "import warnings\n",
    "import holidays\n",
    "from hijri_converter import convert\n",
    "from datetime import date,datetime, timedelta\n",
    "from prophet.diagnostics import performance_metrics, cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33839ac",
   "metadata": {},
   "source": [
    "### ****Importing the dataset****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data for Prophet\n",
    "df = pd.read_csv('/home/ajaz/DemandForecasting/Data/data.csv')\n",
    "data = df.rename(columns={'TransactionDate': 'ds', 'GroupCostPrice': 'y'})  # Rename columns for Prophet compatibility\n",
    "data = data[['ds', 'y']]\n",
    "data['ds']=pd.to_datetime(data['ds'])\n",
    "\n",
    "# # Define the start and end dates for filtering covid  \n",
    "covid_start_date = '2020-03-02'\n",
    "covid_end_date = '2020-06-21'\n",
    "\n",
    "# Filter the data frame to include only the year 2023\n",
    "#data = data[data['ds'].dt.year ==2023]\n",
    "\n",
    "# Get the first and last dates of the filtered data\n",
    "start_date = pd.to_datetime( data['ds'].iloc[0])\n",
    "end_date = pd.to_datetime( data['ds'].iloc[-1])\n",
    "\n",
    "# Extract the first 30 days of the data\n",
    "first_30Days = data.iloc[0:30]\n",
    "\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71839e03",
   "metadata": {},
   "source": [
    "### Detecting Growth  Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb37e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decide whether data['y'] is logistic or linear\n",
    "def get_smooth_data(df, date_column, value_column, window_size=30):\n",
    "    \"\"\"\n",
    "    Smooths the data in the value_column using a rolling mean.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame with a date and a value column.\n",
    "    date_column (str): The name of the column containing date information.\n",
    "    value_column (str): The name of the column containing the data to smooth.\n",
    "    window_size (int): The size of the rolling window to use for smoothing.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A new DataFrame with an additional column 'smoothed_value'.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Ensure the date column is in datetime format\n",
    "    df_copy[date_column] = pd.to_datetime(df_copy[date_column])\n",
    "    \n",
    "    # Set the date column as the index for rolling\n",
    "    df_copy.set_index(date_column, inplace=True)\n",
    "    \n",
    "    # Calculate the rolling mean\n",
    "    df_copy[value_column] = df_copy[value_column].rolling(window=window_size, min_periods=1).mean()\n",
    "    \n",
    "    # Reset the index to return to the original format\n",
    "    df_copy.reset_index(inplace=True)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def logistic_function(x, L, k, x0):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "# Function to detect trend type by passing the dataframe, date column and value column names\n",
    "def detect_trend(df, date_column, value_column):\n",
    "    df['date_ordinal'] = pd.to_datetime(df[date_column]).apply(lambda date: date.toordinal())\n",
    "\n",
    "    # Linear Fit\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(df[['date_ordinal']], df[value_column])\n",
    "    linear_r_squared = linear_model.score(df[['date_ordinal']], df[value_column])\n",
    "    #print(f\"Linear R-squared: {linear_r_squared}\")\n",
    "\n",
    "    if linear_r_squared > 0.70:  # Adjusted threshold\n",
    "        return 'linear'\n",
    "    \n",
    "    # Logistic Fit\n",
    "    try:\n",
    "        popt, _ = curve_fit(logistic_function, df['date_ordinal'], df[value_column], maxfev=10000)\n",
    "        logistic_r_squared = 1 - np.var(np.array(df[value_column]) - logistic_function(df['date_ordinal'], *popt)) / np.var(df[value_column])\n",
    "        #print(f\"Logistic R-squared: {logistic_r_squared}\")\n",
    "\n",
    "        if logistic_r_squared > 0.70:  # Adjusted threshold\n",
    "            return 'logistic'\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error in logistic fit: {e}\")\n",
    "\n",
    "    # Flat Trend\n",
    "    std_dev = df[value_column].std()\n",
    "    mean_val = df[value_column].mean()\n",
    "    #print(f\"Standard Deviation: {std_dev}, Mean: {mean_val}\")\n",
    "\n",
    "    if std_dev < (mean_val * 0.3):  # Adjusted threshold\n",
    "        return 'flat'\n",
    "\n",
    "    return 'Unknown'\n",
    "\n",
    "# loop throgh number from 30 to 100 and find the best window size\n",
    "#window_size=30\n",
    "def get_growth_by_smoothing_data(data):\n",
    "    '''\n",
    "    This function will loop through the window size from 1 to len(data) and find the best window size\n",
    "    the return value will be growth type and the smoothed data and the window size\n",
    "    '''\n",
    "    max_window_size=int(len(data) )\n",
    "    for window_size in range(1,max_window_size):\n",
    "        smooth_df=get_smooth_data(data,'ds','y',window_size=window_size)\n",
    "        newGroth= detect_trend(smooth_df,'ds','y')\n",
    "        if newGroth == 'Unknown':\n",
    "            continue\n",
    "        else:\n",
    "            return newGroth, smooth_df, window_size\n",
    "    return 'Unknown', smooth_df, window_size\n",
    "\n",
    "# if the user passed determineGrowth as true then we will determine the growth type by our method\n",
    "# and if didn't pass true then we will check if the user passed growth type or not\n",
    "\n",
    "# Detect growth pattern\n",
    "if determineGrowth == True:\n",
    "    growth , smooth_df , window_size= get_growth_by_smoothing_data(data)\n",
    "    print (\"The growth was determined by our method\")\n",
    "    print('growth type is ' + growth + ' with window size ' + str(window_size))\n",
    "    plt.plot(smooth_df['ds'], smooth_df['y'], linestyle = 'solid',color='blue')\n",
    "else:\n",
    "    if growth is None:\n",
    "        # throw exception indicates that we need to pass growth type or determineGrowth should be true\n",
    "        raise Exception(\"You should pass growth type one of these values ( linear , logistic or flat) or determineGrowth should be true\" )\n",
    "    else:\n",
    "        print (\"The growth was determined by the user\")\n",
    "        print( 'growth type is ' + growth )\n",
    "\n",
    "\n",
    "# if the growth type is not flat or logistic or linear then we will throw exception\n",
    "if growth not in ['flat','logistic','linear']:\n",
    "    raise Exception(\"growth type should be one of these values ( linear , logistic or flat)\" )\n",
    "\n",
    "plt.plot(data['ds'], data['y'], linestyle = 'solid',color='red')\n",
    "\n",
    "# a line plot like a trend over the time monthly\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('time')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508bd75",
   "metadata": {},
   "source": [
    "### Detecting Change points Parameter using PELT Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769fec6",
   "metadata": {},
   "source": [
    "PELT algorithm is utilized for changepoint detection in the trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the penalty for changepoint detection based on sensitivity level and predefined coefficients\n",
    "\n",
    "def calculate_penalty(data, sensitivity, cal=[6, 3, 1.5]):\n",
    "    if sensitivity == \"Low\":\n",
    "        return cal[0] * math.log(len(data))\n",
    "    elif sensitivity == \"Medium\":\n",
    "        return cal[1] * math.log(len(data))\n",
    "    elif sensitivity == \"High\":\n",
    "        return cal[2] * math.log(len(data))\n",
    "\n",
    "peltdata = data['y'].values\n",
    "# You can choose between \"l1\" and \"l2\" cost functions\n",
    "\n",
    "algo = rpt.Pelt(model=pltModelType, min_size=1, jump=1).fit(peltdata)\n",
    "penalty= calculate_penalty(peltdata, PenaltySensitivity)\n",
    "result = algo.predict(pen=3)\n",
    "\n",
    "changepointDates=[]\n",
    "for index in result:\n",
    "    a=data.iloc[index-1]['ds']\n",
    "    changepointDates.append(a)\n",
    "\n",
    "changepointDates=pd.DataFrame(changepointDates, columns=['ds'])\n",
    "changepointDates['ds'] = pd.to_datetime(changepointDates['ds'])\n",
    "\n",
    "changepoints=changepointDates['ds']\n",
    "daysInChangepoints=first_30Days.loc[first_30Days['ds'].isin(changepoints)]\n",
    "\n",
    "plt.plot(first_30Days['ds'],first_30Days['y'] )\n",
    "plt.scatter(daysInChangepoints['ds'],daysInChangepoints['y'], marker='v', color='r')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "daysInChangepoints.head(2)\n",
    "#holidays=holidays\n",
    "#changepointDates.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf5a6f",
   "metadata": {},
   "source": [
    "# Outlier\n",
    "##### Original Data Filtered by the Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if detectoutliers:\n",
    "    #plot like a fot not as a line for data['ds'], data['y']  ds on x axis and y on y axis, dont join the line only the points\n",
    "    plt.scatter(data['ds'], data['y'], linestyle = 'solid',color='red')\n",
    "    #increase the width of the plot\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15, 5)\n",
    "\n",
    "    print(data['y'].describe())\n",
    "    Q1 = data['y'].quantile(0.25)\n",
    "    Q3 = data['y'].quantile(0.75)\n",
    "    QCustom99= data['y'].quantile(0.99)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - IQRRange * IQR\n",
    "    upper_bound = Q3 + IQRRange * IQR\n",
    "    soutliers = data[((data['y'] < lower_bound) | (data['y'] > upper_bound))]\n",
    "\n",
    "    # Identifying outliers\n",
    "    outliers = data[((data['y'] < lower_bound) | (data['y'] > upper_bound))]\n",
    "\n",
    "    # Replace outlier values with the mean\n",
    "    data.loc[outliers.index, 'y'] = data['y'].mean()\n",
    "\n",
    "\n",
    "    plt.scatter(data['ds'], data['y'], linestyle = 'solid',color='green')\n",
    "    #plt.scatter(data['ds'], data['y'], linestyle = 'solid',color='red')\n",
    "\n",
    "\n",
    "    print('CustomQuartile99 < 99% : ' + str(QCustom99))\n",
    "    print('IQR : ' + str(IQR))\n",
    "\n",
    "    print('Number of Outliers :' + str(len(soutliers)))\n",
    "    print('Number of rows in data : ' + str(len(data)))\n",
    "    print('lower_bound : ' + str(lower_bound))\n",
    "    print('upper_bound : ' + str(upper_bound))\n",
    "    print(outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1b7f5",
   "metadata": {},
   "source": [
    "## Generate Ramadan Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f8cf9",
   "metadata": {},
   "source": [
    "The function generate_ramadan_dates_df(start_year, end_year) generates a DataFrame of Ramadan dates in the Gregorian calendar for a given range of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f656abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ramadan_dates_df(start_year, end_year):\n",
    "    ramadan_dates = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # The Umm al-Qura calendar uses Hijri dates for Islamic months\n",
    "        hijri_year_start = convert.Gregorian(year, 1, 1).to_hijri()\n",
    "        hijri_year_end = convert.Gregorian(year, 12, 30).to_hijri()\n",
    "\n",
    "        for day in range(1, 30):  # Assuming Ramadan lasts for 29 or 30 days\n",
    "            # Find the date of Ramadan in the Hijri calendar\n",
    "            ramadan_date = convert.Hijri(hijri_year_start.year, 9, day).to_gregorian()\n",
    "\n",
    "            # Append the date to the list\n",
    "            ramadan_dates.append(ramadan_date)\n",
    "\n",
    "    # Create a DataFrame with a column named 'ramadan_dates'\n",
    "    ramadan_df = pd.DataFrame({'ds': ramadan_dates})\n",
    "    return ramadan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = start_date.year\n",
    "end_year = end_date.year\n",
    "ramadan_df = generate_ramadan_dates_df(start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d0a71",
   "metadata": {},
   "source": [
    "## Generate the Weekend Days Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4aa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weekends(start_date, end_date, weekend_days):\n",
    "    '''\n",
    "    This function will generate weekends dataframe with ds and holiday columns\n",
    "    Parameters : \n",
    "    start_date : start date of the data of type datetime\n",
    "    end_date : end date of the data of type datetime\n",
    "    weekend_days : list of weekend days ex: [4] for Friday\n",
    "    return : weekends dataframe with ds and holiday columns\n",
    "    '''\n",
    "    weekends = []\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Check if the current date is a weekend\n",
    "        if current_date.weekday() in weekend_days:\n",
    "            weekends.append(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Create a DataFrame with day names and dates\n",
    "    weekend_df = {'ds': weekends,\n",
    "                  'holiday': [day.strftime('%A') for day in weekends]}\n",
    "\n",
    "    df_weekends = pd.DataFrame(weekend_df)\n",
    "    return df_weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0266e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(start_date))\n",
    "df_weekends = generate_weekends(start_date, end_date, weekend_days)\n",
    "data['is_weekend'] = data['ds'].isin(df_weekends['ds']).astype(int)\n",
    "data['is_weekday'] = (data['is_weekend'] == 0).astype(int)\n",
    "\n",
    "weekendDaysCount= len(weekend_days)\n",
    "workingDaysCount= 7 - weekendDaysCount\n",
    "\n",
    "\n",
    "first_30Days['is_weekend'] = first_30Days['ds'].isin(df_weekends['ds']).astype(int)\n",
    "\n",
    "onlyWeekends= first_30Days[data['is_weekend']==1]\n",
    "\n",
    "plt.plot(first_30Days['ds'],first_30Days['y'])\n",
    "plt.scatter(onlyWeekends['ds'],onlyWeekends['y'], marker='v', color='r')\n",
    "#increase the width of the plot\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7d7fa",
   "metadata": {},
   "source": [
    "#### Carrying Capacity Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b500580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a percentile value (e.g., 99th percentile)\n",
    "percentile_value = 99\n",
    "\n",
    "# Calculate the specified percentile for the cap\n",
    "cap = (np.percentile(data['y'], percentile_value)) * 1.5\n",
    "\n",
    "# Define a lower percentile value (e.g., 5th percentile) for the floor\n",
    "percentile_floor = 5\n",
    "\n",
    "# Calculate the specified percentile for the floor\n",
    "floor = np.percentile(data['y'], percentile_floor)\n",
    "\n",
    "#print (prophet_data[prophet_data['y'] == 0])\n",
    "\n",
    "#prophet_data['cap']=cap\n",
    "#prophet_data['floor']=floor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c521f5",
   "metadata": {},
   "source": [
    "#### Adding  Ramadan dates in prophet Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_ramadan'] = data['ds'].isin(ramadan_df['ds']).astype(int)\n",
    "prophet_data= data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18da56",
   "metadata": {},
   "source": [
    "# **Training Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d797c",
   "metadata": {},
   "source": [
    "#### ****Initialize the Model**** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Prophet model with the filtered parameters\n",
    "prophetModel = Prophet(**prophet_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb73b6",
   "metadata": {},
   "source": [
    "### ****Custom  Seasonalties****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30307f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the  passed condition is True or Not none then it  execute the below code\n",
    "#Check the names of the variables from the variables\n",
    "\n",
    "if country_name:\n",
    "    prophetModel.add_country_holidays(country_name=country_name)\n",
    "\n",
    "if yearly_add_seasonality:\n",
    "    prophetModel.add_seasonality(name='yearly_season' ,period=yearly_season_period ,fourier_order=yearly_season_fourier_order )\n",
    "\n",
    "if quarterly_add_seasonality:\n",
    "    prophetModel.add_seasonality(name='quarterly_season' ,period=quarterly_season_period ,fourier_order=quarterly_season_fourier_order )\n",
    "\n",
    "if monthly_add_seasonality:\n",
    "    prophetModel.add_seasonality(name='monthly_season' ,period=monthly_season_period ,fourier_order=monthly_season_fourier_order )\n",
    "\n",
    "if Weekend_add_seasonality:\n",
    "    prophetModel.add_seasonality(name='Weekends_season' ,period=weekendDaysCount ,fourier_order=Weekends_fourier_order ,condition_name='is_weekend')\n",
    "\n",
    "if WorkingDays_add_seasonality:\n",
    "    prophetModel.add_seasonality(name='WorkingDays_season' ,period=workingDaysCount ,fourier_order=WorkingDays_fourier_order ,condition_name='is_weekday')\n",
    "\n",
    "if ramadan_add_seasonality:\n",
    "    prophetModel.add_seasonality(name='ramadan_season' ,period=ramadan_period ,fourier_order=ramadan_fourier_order ,condition_name='is_ramadan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409559bb",
   "metadata": {},
   "source": [
    "#### ****Fit the model to the data**** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63920a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric=prophetModel.fit(prophet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903aa2fc",
   "metadata": {},
   "source": [
    "# Generate future Dataframe Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate future dates\n",
    "\n",
    "future_df = prophetModel.make_future_dataframe(periods=30)\n",
    "firstdate=future_df['ds'].iloc[0]\n",
    "lastdate=future_df['ds'].iloc[-1]\n",
    "future_weekends = generate_weekends(firstdate, lastdate, weekend_days)\n",
    "\n",
    "future_df['is_ramadan'] = future_df['ds'].isin(ramadan_df['ds']).astype(int)\n",
    "\n",
    "#future_df['cap'] = cap\n",
    "#future_df['floor'] = floor\n",
    "\n",
    "# Add the 'holidays' column to the future DataFrame\n",
    "#future_df['holidays'] = 0\n",
    "#future_df.loc[future_df['ds'].isin(df_weekends['ds']), 'holidays'] = 1\n",
    "\n",
    "future_df['is_weekend'] = future_df['ds'].isin(future_weekends['ds']).astype(int)\n",
    "future_df['is_weekday'] = (future_df['is_weekend'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba85af",
   "metadata": {},
   "source": [
    "## ****Cross Validation****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a419b",
   "metadata": {},
   "source": [
    "Need to generate mape values to finally decide about the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4410459",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cv = cross_validation(prophetModel, initial='730 days', period='180 days', horizon = '30 days')\n",
    "df_p = performance_metrics(df_cv)\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = performance_metrics(df_cv)\n",
    "#Mean MAPE across all horizons\n",
    "mean_mape = np.mean(df_p['smape'])\n",
    "# Median MAPE (more robust to outliers)\n",
    "MAPEresult = np.median(df_p['smape'])\n",
    "#format the variable as a percentage\n",
    "mean_mape = \"{:.2%}\".format(mean_mape)\n",
    "MAPEresult = \"{:.2%}\".format(MAPEresult)\n",
    "#print(\"Median MAPE: \" + str(MAPEresult))\n",
    "print(\"Mean MAPE: \" + str(mean_mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84172c38",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6dbe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate predictions\n",
    "forecast = prophetModel.predict(future_df)\n",
    "\n",
    "prophetModel.plot(forecast)\n",
    "prophetModel.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555bae",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Comparision of Actual And Predicted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7faccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create comment for the following code\n",
    "### Analyze and visualize results\n",
    "\n",
    "#forecast.to_csv('/home/ajaz/DemandForecasting/Data/Output/forecast.csv')\n",
    "\n",
    "actualdata = pd.read_csv('/home/ajaz/DemandForecasting/Data/actualdata.csv')\n",
    "actualdata = actualdata.rename(columns={'TransactionDate': 'ds', 'GroupCostPrice': 'actual'})\n",
    "actualdata['ds']=pd.to_datetime(actualdata['ds'])\n",
    "\n",
    "#predicteddata =forecast[['ds', 'yhat']].tail(30)\n",
    "forecast = forecast.rename(columns={'ds': 'ds', 'yhat': 'predicted'})\n",
    "forecast['ds']=pd.to_datetime(forecast['ds'])\n",
    "\n",
    "finaldata = pd.merge(actualdata,forecast.tail(30),on='ds')\n",
    "\n",
    "finaldata.plot(x='ds', y=['actual', 'predicted','trend','yhat_lower','yhat_upper'], kind='line', title='Actual vs Predicted')\n",
    "#show the day name x axis\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Date')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "# print the rows with negative values \n",
    "\n",
    "#finaldata.to_csv('/home/ajaz/DemandForecasting/Data/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
