{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05879227",
   "metadata": {},
   "source": [
    "# `Neural-Prophet` Machine Learning Model Documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfa77f",
   "metadata": {},
   "source": [
    "# **Neural Prophet Parameters**\n",
    "### ******Input Parameters from Interface******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e1626",
   "metadata": {},
   "source": [
    "#### NeuralProphet Parameters Description\n",
    "\n",
    "Here's a detailed description of the parameters for the NeuralProphet time series forecasting model:\n",
    "\n",
    "1. **Growth Parameters:**\n",
    "   - `growth`: Determines the trend growth type. Options are 'off' (no trend), 'linear' (linear growth), 'discontinuous' (discontinuous growth).\n",
    "\n",
    "2. **Changepoints Parameters:**\n",
    "   - `changepoints`: List of specific dates to include as potential changepoints.\n",
    "   - `n_changepoints`: Number of potential changepoints to automatically select.\n",
    "   - `changepoints_range`: Proportion of history in which to select potential changepoints.\n",
    "\n",
    "3. **Seasonality Parameters:**\n",
    "   - `yearly_seasonality`: Automatically include yearly seasonality (set to 'auto' for automatic detection).\n",
    "   - `weekly_seasonality`: Automatically include weekly seasonality.\n",
    "   - `daily_seasonality`: Automatically include daily seasonality.\n",
    "   - `seasonality_mode`: Type of seasonality, either 'additive' or 'multiplicative'.\n",
    "   - `seasonality_reg`: Regularization term for seasonality.\n",
    "\n",
    "4. **Confidence Interval Parameters:**\n",
    "   - `confidence_lv`: Confidence level for prediction intervals.\n",
    "   - `quantiles`: List of quantiles for prediction intervals.\n",
    "\n",
    "5. **Missing Data Handling:**\n",
    "   - `impute_missing`: Whether to impute missing values.\n",
    "   - `impute_linear`: Number of data points to impute using linear interpolation.\n",
    "   - `impute_rolling`: Number of data points to impute using rolling window mean.\n",
    "   - `drop_missing`: Whether to drop missing values.\n",
    "\n",
    "6. **Normalization Parameters:**\n",
    "   - `normalize`: Type of normalization to apply ('auto', 'soft', 'soft1', 'minmax', 'standardize', 'off').\n",
    "\n",
    "7. **Lags and Forecasts:**\n",
    "   - `n_lags`: Number of lagged observations to include.\n",
    "   - `n_forecasts`: Number of steps ahead to forecast.\n",
    "\n",
    "8. **Autoregression Parameters:**\n",
    "   - `ar_layers`: List of autoregressive layers.\n",
    "   - `ar_reg`: Regularization term for autoregressive layers.\n",
    "   - `lagged_reg_layers`: List of layers for lagged regularization.\n",
    "\n",
    "9. **Training Parameters:**\n",
    "   - `learning_rate`: Learning rate for model training.\n",
    "   - `epochs`: Number of training epochs.\n",
    "   - `batch_size`: Batch size for training.\n",
    "   - `loss_func`: Loss function for training.\n",
    "   - `optimizer`: Optimizer for training.\n",
    "\n",
    "10. **Global/Local Parameters:**\n",
    "    - `season_global_local`: Type of seasonality ('global' or 'local').\n",
    "    - `trend_global_local`: Type of trend ('global' or 'local').\n",
    "\n",
    "11. **Trend Parameters:**\n",
    "    - `trend_reg`: Regularization term for the trend.\n",
    "    - `trend_reg_threshold`: Threshold for trend regularization.\n",
    "    - `newer_samples_weight`: Weight for newer samples in the trend.\n",
    "    - `newer_samples_start`: Starting point for applying newer samples weight.\n",
    "\n",
    "12. **Additional Configuration:**\n",
    "    - `collect_metrics`: Specify whether to collect metrics during training.\n",
    "    - `global_normalization`: Type of global normalization.\n",
    "    - `global_time_normalization`: Type of global time normalization.\n",
    "    - `unknown_data_normalization`: Type of normalization for unknown data.\n",
    "    - `accelerator`: Acceleration type for training.\n",
    "    - `trainer_config`: Configuration for the trainer.\n",
    "    - `prediction_frequency`: Frequency of predictions during training.\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf90fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NeuralProphet\n",
    "\n",
    "#Excel file Path\n",
    "file_path= '/home/ajaz/DemandForecasting/Data/sampledata.csv'    \n",
    " \n",
    "#1. **Growth Parameters:**\n",
    "detectGrowth=True #bool\n",
    "growth='off'  #Literal['off', 'linear', 'discontinuous']\n",
    "\n",
    "#2. **Changepoints Parameters:**\n",
    "detectChangepoints=True #bool\n",
    "changepoints= None #Optional[list]\n",
    "n_changepoints =None    #0, #int\n",
    "changepoints_range=None     #0.8 #float\n",
    "\n",
    "#3. **Seasonality Parameters:**\n",
    "#To Control Seasonality\n",
    "yearly_seasonality= None  #'auto'ss\n",
    "weekly_seasonality= None   #'auto'\n",
    "daily_seasonality = None   #'auto'\n",
    "\n",
    "seasonality_mode='multiplicative' #['additive', 'multiplicative']\n",
    "seasonality_reg= None    #float 0\n",
    "\n",
    "#4. **Confidence Interval Parameters:**\n",
    "confidence_lv = 0.9\n",
    "#quantiles  = None      #[]   #List[float]\n",
    "quantiles = [round(((1 - confidence_lv) / 2), 2), round((confidence_lv + (1 - confidence_lv) / 2), 2)]\n",
    "\n",
    "#5. **Missing Data Handling:**\n",
    "impute_missing= None,     #bool\n",
    "impute_linear = None,    #int\n",
    "impute_rolling= None,  #int\n",
    "drop_missing  = None   #bool\n",
    "\n",
    "#6. **Normalization Parameters:**\n",
    "normalize=None         #'off'     # Literal['auto', 'soft', 'soft1', 'minmax', 'standardize', 'off']\n",
    "\n",
    "#7. **Lags and Forecasts:**\n",
    "n_lags=None        #0    # int 0    \n",
    "n_forecasts=None   #0 #int 1\n",
    "\n",
    "#8. **Autoregression Parameters:**  \n",
    "ar_layers=None     #[]    #Optional[list]   \n",
    "ar_reg= None       #Optional[float]     \n",
    "lagged_reg_layers= None    #[]   #Optional[list]       \n",
    "learning_rate= 0.1   #Optional[float]\n",
    "\n",
    "#9. **Training Parameters:**\n",
    "epochs= None      #Optional[int]\n",
    "batch_size= None   #Optional[int]\n",
    "loss_func=None     #'Huber'\n",
    "optimizer=None     #'AdamW'\n",
    "\n",
    "#10. **Global/Local Parameters:**\n",
    "season_global_local=None #['global', 'local']\n",
    "trend_global_local= None   #str 'global', 'local'\n",
    "\n",
    "#11. **Trend Parameters:**\n",
    "trend_reg= None  #Optional[float]\n",
    "trend_reg_threshold =None  #Optional[Union[bool, float]]\n",
    "newer_samples_weight= None  # float\n",
    "newer_samples_start =None   #float\n",
    "\n",
    "#12. **Additional Configuration:**\n",
    "collect_metrics= None      #Union [bool, list, dict]\n",
    "\n",
    "global_normalization=None\n",
    "global_time_normalization=None\n",
    "unknown_data_normalization=None\n",
    "\n",
    "accelerator=None  #Optional[str] None\n",
    "trainer_config=None # dict {},\n",
    "prediction_frequency=None  # Optional[dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978d190",
   "metadata": {},
   "source": [
    "# Additional Seasonality Regressors Parameters Description\n",
    "\n",
    "Here's a detailed description of the parameters related to additional seasonality regressors, including custom holidays:\n",
    "\n",
    "1. **Custom Holidays:**\n",
    "   - `country_name`: Country code (ISO 3166-2) for custom holidays.\n",
    "\n",
    "2. **Yearly Seasonality Parameters:**\n",
    "   - `yearly_add_seasonality`: Whether to include yearly seasonality.\n",
    "   - `yearly_season_period`: Length of the yearly season in days.\n",
    "   - `yearly_season_fourier_order`: Number of Fourier series components for modeling yearly seasonality.\n",
    "\n",
    "****Similarly for the below seasonalities:****\n",
    "\n",
    "3. **Quarterly Seasonality Parameters:**\n",
    "4. **Monthly Seasonality Parameters:**\n",
    "5. **Weekend Seasonality Parameters:**\n",
    "6. **Working Days Seasonality Parameters:**\n",
    "7. **Ramadan Seasonality Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9934b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional  Seasonality regressors\n",
    "\n",
    "#Custom holidays\n",
    "country_name= 'SA'   #   'SA' # Country Code  (ISO 3166-2) for holidayss\n",
    "\n",
    "yearly_add_seasonality=True\n",
    "yearly_season_period=365.25\n",
    "yearly_season_fourier_order=2\n",
    "\n",
    "quarterly_add_seasonality=False\n",
    "quarterly_season_period=None\n",
    "quarterly_season_fourier_order=None\n",
    "\n",
    "monthly_add_seasonality=False\n",
    "monthly_season_period=None\n",
    "monthly_season_fourier_order=None\n",
    "\n",
    "# Weekend days (0-6, Mon-Sun)\n",
    "weekend_days = [4]  # 4 is Friday\n",
    "\n",
    "Weekend_add_seasonality=False\n",
    "weekendDaysCount=1\n",
    "Weekends_fourier_order=5\n",
    "\n",
    "WorkingDays_add_seasonality=False\n",
    "workingDaysCount=6\n",
    "WorkingDays_fourier_order=5\n",
    "\n",
    "ramadan_add_seasonality=False\n",
    "ramadan_period=29.33\n",
    "ramadan_fourier_order=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc4e0f",
   "metadata": {},
   "source": [
    "#### ******Parameters used in other calc, other than the model******\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91cf935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty sensitivity for PELT algorithm: 'High', 'Medium', 'Low' : Used to determine the penalty value for the PELT algo which is used for changepoint detection\n",
    "PenaltySensitivity =\"High\"  \n",
    "\n",
    "# Model type for changepoint detection: 'l1' (linear 1), 'l2' (linear 2), 'rbf' (radial basis function)\n",
    "pltModelType = \"l2\"  # \"l2\", \"rbf\"\n",
    "\n",
    "detectOutliers =False # If True, outliers are detected and removed from the data else outliers are not detected and not removed from the data\n",
    "\n",
    "#IQR stands for Interquartile Range, which is a measure of statistical dispersion of data\n",
    "#IQR Range for outlier detection (1.5 is default) 3 is too high ,  upper_bound = Q3 + IQRRange * IQR and lower_bound = Q1 - IQRRange * IQR \n",
    "\n",
    "IQRRange=1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5bf95",
   "metadata": {},
   "source": [
    "# ****Prophet Algorithm****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c065b3",
   "metadata": {},
   "source": [
    "### ****Importing Libraries****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e0c3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import ruptures as rpt\n",
    "import warnings\n",
    "import holidays\n",
    "from hijri_converter import convert\n",
    "from datetime import date,datetime, timedelta\n",
    "from prophet.diagnostics import performance_metrics, cross_validation\n",
    "\n",
    "#import myModule as myModule\n",
    "from myModule.fileIO import loadCsvExcelFile \n",
    "from myModule.dataAnalysis import detectGrowth \n",
    "\n",
    "from myModule.dataAnalysis import detectChangepoints\n",
    "from myModule.dataAnalysis import detectOutliers\n",
    "from myModule.dateGeneration import generateRamadanDates\n",
    "from myModule.dateGeneration import generateWeekends\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33839ac",
   "metadata": {},
   "source": [
    "### ****Importing the dataset****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c07e6a",
   "metadata": {},
   "source": [
    "##### Importing Data using the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73537195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>50930.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>73204.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>60450.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>101558.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds          y\n",
       "0 2018-01-01   50930.49\n",
       "1 2018-01-02   73204.65\n",
       "2 2018-01-03   60450.73\n",
       "3 2018-01-04  101558.60\n",
       "4 2018-01-05       0.00"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/ajaz/DemandForecasting/Data/sampledata.csv\"\n",
    "\n",
    "#Load Data \n",
    "data = loadCsvExcelFile(file_path)\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data.rename(columns={'date':'ds','value':'y'},inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f01bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth Detected :  linear\n"
     ]
    }
   ],
   "source": [
    "#Growth Detection\n",
    "if detectGrowth:\n",
    "    growth = detectGrowth(data)\n",
    "    print(\"Growth Detected : \",growth)\n",
    "else:\n",
    "    print(\"Manual, Growth Detection is Off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7b04a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully detected Change points\n",
      "Change points :  0      2018-01-01\n",
      "1      2018-01-02\n",
      "2      2018-01-03\n",
      "3      2018-01-04\n",
      "4      2018-01-05\n",
      "          ...    \n",
      "1981   2023-07-27\n",
      "1982   2023-07-28\n",
      "1983   2023-07-29\n",
      "1984   2023-07-30\n",
      "1985   2023-07-31\n",
      "Name: ds, Length: 1986, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#detect Change points\n",
    "if detectChangepoints:\n",
    "    changepoints= detectChangepoints(data, pltModelType, PenaltySensitivity)\n",
    "    print(\"Sucessfully detected Change points\")\n",
    "    print(\"Change points : \",changepoints)\n",
    "else:\n",
    "    print(\"Manual, Change points Detection is Off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47e7b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      2038.000000\n",
      "mean      66087.199681\n",
      "std       59231.218862\n",
      "min           0.000000\n",
      "25%       13084.537500\n",
      "50%       52054.130000\n",
      "75%      110176.500000\n",
      "max      347483.000000\n",
      "Name: y, dtype: float64\n",
      "Sucessfully Removed the Outliers\n",
      "Outlier Detection  is disabled\n"
     ]
    }
   ],
   "source": [
    "#detect Outliers\n",
    "if detectOutliers:\n",
    "    lower_bound, upper_bound = detectOutliers(data, IQRRange)\n",
    "    outliers = data[((data['y'] < lower_bound) | (data['y'] > upper_bound))]\n",
    "    data.loc[outliers.index, 'y'] = data['y'].mean()\n",
    "    print(\"Sucessfully Removed the Outliers\")\n",
    "print(\"Outlier Detection  is disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "602687f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramadan Seasonality is disabled\n"
     ]
    }
   ],
   "source": [
    "#Fix the variables startYear from input Parameters\n",
    "startYear = 2018\n",
    "endYear = 2024\n",
    "\n",
    "if ramadan_add_seasonality:\n",
    "    ramadan_df = generateRamadanDates(startYear, endYear)\n",
    "    data['is_ramadan'] = data['ds'].isin(ramadan_df['ds']).astype(int)\n",
    "    print(\"Sucessfully Added Ramadan dates in prophet Training Data\")\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"Ramadan Seasonality is disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42e6fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend Seasonality is disabled\n",
      "Working days Seasonality is disabled\n"
     ]
    }
   ],
   "source": [
    "#Variables for Weekend and Working days must be imported from input parameters\n",
    "startDate = '2018-01-01'\n",
    "endDate = '2023-07-31'\n",
    "weekendDays = [4]  # 4 is Friday\n",
    "\n",
    "if Weekend_add_seasonality:\n",
    "    df_weekends = generateWeekends(startDate, endDate, *weekendDays)\n",
    "    data['is_weekend'] = data['ds'].isin(df_weekends['ds']).astype(int)  \n",
    "    print(\"Sucessfully Added Weekend dates in prophet Training Data\")\n",
    "else:\n",
    "    print(\"Weekend Seasonality is disabled\")\n",
    "\n",
    "if WorkingDays_add_seasonality:\n",
    "    data['is_weekday'] = (data['is_weekend'] == 0).astype(int)\n",
    "    print(\"Sucessfully Added Working days in prophet Training Data\")\n",
    "else:\n",
    "    print(\"Working days Seasonality is disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53c3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29e84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb726f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f73852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bb70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fe0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875b851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25def345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507a4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a92f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a10ca28",
   "metadata": {},
   "source": [
    "#### ****Method to Import Excel and CSV File****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83027b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file , checking if it is a CSV or Excel file, checking if it is empty, checking if it has required columns\n",
    "#Returns a DataFrame with only the required columns\n",
    "#User can input a path to a CSV or Excel file\n",
    "#Mandatory columns: date, value\n",
    "#Will Generalize in the future to accept more columns and to accept more file types and to accept more data sources\n",
    "\n",
    "def loadCsvExcelFile(file_path):\n",
    "    while True:\n",
    "        try:\n",
    "            # Read file path from the user\n",
    "            file_path=file_path\n",
    "            #file_path = input(\"Enter the path of the Excel or CSV file: \")\n",
    "\n",
    "            # Try to import the file as a DataFrame\n",
    "            try:\n",
    "                if file_path.lower().endswith('.csv'):\n",
    "                    df = pd.read_csv(file_path)\n",
    "                elif file_path.lower().endswith(('.xls', '.xlsx')):\n",
    "                    df = pd.read_excel(file_path)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                raise ValueError(\"The file is empty.\")\n",
    "\n",
    "            # Check if DataFrame has required columns\n",
    "            if 'date' not in df.columns or 'value' not in df.columns:\n",
    "                raise ValueError(\"The DataFrame must have columns named 'date' and 'value'.\")\n",
    "\n",
    "            # Return the resulting DataFrame\n",
    "            return df[['date', 'value']]\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: File not found. Please provide a valid file path.\")\n",
    "        except pd.errors.ParserError:\n",
    "            raise ValueError(\"Error reading the file. Please check if it is a valid CSV or Excel file.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retry = input(\"Do you want to try again? (y/n): \").lower()\n",
    "            if retry != 'y':\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d43ac",
   "metadata": {},
   "source": [
    "### Read the Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "try:\n",
    "    result_df = loadCsvExcelFile (file_path)\n",
    "    print('Sucessfully read the file')\n",
    "except ValueError as ve:\n",
    "    print('Un Sucessfull in reading the file')\n",
    "    print(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result_df.copy()\n",
    "data = data.rename(columns={'date': 'ds', 'value': 'y'})  # Rename columns for Prophet compatibility\n",
    "data['ds'] = pd.to_datetime(data['ds'])  # Convert to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab10ac8",
   "metadata": {},
   "source": [
    "#### Old Method to Read the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Load and prepare the data for Prophet\n",
    "df = pd.read_csv('/home/ajaz/DemandForecasting/Data/data.csv')\n",
    "data = df.rename(columns={'TransactionDate': 'ds', 'GroupCostPrice': 'y'})  # Rename columns for Prophet compatibility\n",
    "data = data[['ds', 'y']]\n",
    "data['ds']=pd.to_datetime(data['ds'])\n",
    "\n",
    "#Copy the dataframe data\n",
    "data_copy = data.copy()\n",
    "\"\"\" \n",
    "\n",
    "# # Define the start and end dates for filtering covid  \n",
    "covid_start_date = '2020-03-02'\n",
    "covid_end_date = '2020-06-21'\n",
    "\n",
    "# Filter the data frame to include only the year 2023\n",
    "#data = data[data['ds'].dt.year ==2023]\n",
    "\n",
    "# Get the first and last dates of the filtered data\n",
    "start_date = pd.to_datetime( data['ds'].iloc[0])\n",
    "end_date = pd.to_datetime( data['ds'].iloc[-1])\n",
    "\n",
    "# Extract the first 30 days of the data\n",
    "first_30Days = data.iloc[0:30]\n",
    "\n",
    "data.head(2)\n",
    "#plt = data.plot(x=\"ds\", y=\"y\", figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487a567e",
   "metadata": {},
   "source": [
    "## Detecting Growth Param: detectGrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969abdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectGrowth(data, threshold=0.5, window_size=7):\n",
    "    \"\"\"\n",
    "    Detects the growth type based on the rolling mean trend of a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame, the input data.\n",
    "    - threshold: float, a threshold to categorize the growth type.\n",
    "    - window_size: int, the window size for calculating the rolling mean.\n",
    "\n",
    "    Returns:\n",
    "    - str, the detected growth type.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy of the data\n",
    "    growth_df = data.copy()\n",
    "\n",
    "    # Calculate the rolling mean with a specified window size\n",
    "    growth_df['rolling_mean'] = growth_df['y'].rolling(window=window_size).mean()\n",
    "\n",
    "    # Determine growth type based on the rolling mean trend\n",
    "    mean_diff = growth_df['rolling_mean'].diff().mean()\n",
    "\n",
    "    # Categorize the growth type\n",
    "    if abs(mean_diff) < threshold:\n",
    "        growth = 'flat'\n",
    "    elif mean_diff != 0:\n",
    "        growth = 'linear'\n",
    "    else:\n",
    "        growth = 'discontinuous'\n",
    "\n",
    "    # Return the detected growth type\n",
    "    return growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0975b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "#mM.dataAnalysis.detectGrowth(data)\n",
    "growth = detectGrowth(data)\n",
    "print(f\"The growth type is '{growth}'.\")\n",
    "growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "growth_df=data.copy()\n",
    "#copy the data dataframe to growth_df\n",
    "\n",
    "# Set a suitable threshold based on the characteristics of your data\n",
    "threshold = 0.5  # You may need to adjust this based on your specific use case \n",
    "\n",
    "# Calculate the rolling mean with a window size (adjust as needed)\n",
    "window_size = 7\n",
    "growth_df['rolling_mean'] = growth_df['y'].rolling(window=window_size).mean()\n",
    "\n",
    "# Determine growth type based on the rolling mean trend\n",
    "mean_diff = growth_df['rolling_mean'].diff().mean()\n",
    "\n",
    "# Categorize the growth type\n",
    "if abs(mean_diff) < threshold:\n",
    "    growth = 'flat'\n",
    "elif mean_diff != 0:\n",
    "    growth = 'linear'\n",
    "else:\n",
    "    growth = 'discontinuous' \n",
    "# Print the result\n",
    "print(f\"The growth type is '{growth}'.\")\n",
    "\n",
    "\n",
    "# Plot the time series data and rolling mean\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(growth_df['ds'], growth_df['y'], label='Original Data')\n",
    "plt.plot(growth_df['ds'], growth_df['rolling_mean'], label=f'Rolling Mean (window={window_size})', color='orange')\n",
    "plt.title('Time Series Data and Rolling Mean')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f4c8a",
   "metadata": {},
   "source": [
    "## Detecting Change points Parameter using ****PELT**** Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca960e",
   "metadata": {},
   "source": [
    "### Old Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed78f9",
   "metadata": {},
   "source": [
    "PELT algorithm is utilized for changepoint detection in the trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the penalty for changepoint detection based on sensitivity level and predefined coefficients\n",
    "\n",
    "def calculate_penalty(data, sensitivity, cal=[6, 3, 1.5]):\n",
    "    if sensitivity == \"Low\":\n",
    "        return cal[0] * math.log(len(data))\n",
    "    elif sensitivity == \"Medium\":\n",
    "        return cal[1] * math.log(len(data))\n",
    "    elif sensitivity == \"High\":\n",
    "        return cal[2] * math.log(len(data))\n",
    "\n",
    "peltdata = data['y'].values\n",
    "\n",
    "# You can choose between \"l1\" and \"l2\" cost functions\n",
    "algo = rpt.Pelt(model=pltModelType, min_size=1, jump=1).fit(peltdata)\n",
    "penalty= calculate_penalty(peltdata, PenaltySensitivity)\n",
    "result = algo.predict(pen=3)\n",
    "\n",
    "changepointDates=[]\n",
    "for index in result:\n",
    "    a=data.iloc[index-1]['ds']\n",
    "    changepointDates.append(a)\n",
    "\n",
    "changepointDates=pd.DataFrame(changepointDates, columns=['ds'])\n",
    "changepointDates['ds'] = pd.to_datetime(changepointDates['ds'])\n",
    "changepoints=changepointDates['ds']\n",
    "\n",
    "# Plot the changepoints on the time series data\n",
    "\n",
    "daysInChangepoints=first_30Days.loc[first_30Days['ds'].isin(changepoints)]\n",
    "\n",
    "plt.plot(first_30Days['ds'],first_30Days['y'] )\n",
    "plt.scatter(daysInChangepoints['ds'],daysInChangepoints['y'], marker='v', color='r')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "daysInChangepoints.head(2)\n",
    "#holidays=holidays\n",
    "#changepointDates.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b56eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4dc10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541df3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the changepoints on the time series data\n",
    "\n",
    "daysInChangepoints=first_30Days.loc[first_30Days['ds'].isin(changepoints)]\n",
    "\n",
    "plt.plot(first_30Days['ds'],first_30Days['y'] )\n",
    "plt.scatter(daysInChangepoints['ds'],daysInChangepoints['y'], marker='v', color='r')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "daysInChangepoints.head(2)\n",
    "#holidays=holidays\n",
    "#changepointDates.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1b7f5",
   "metadata": {},
   "source": [
    "## Generate Ramadan Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f8cf9",
   "metadata": {},
   "source": [
    "The function generate_ramadan_dates_df(start_year, end_year) generates a DataFrame of Ramadan dates in the Gregorian calendar for a given range of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ebc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ramadan_dates_df(start_year, end_year):\n",
    "    ramadan_dates = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # The Umm al-Qura calendar uses Hijri dates for Islamic months\n",
    "        hijri_year_start = convert.Gregorian(year, 1, 1).to_hijri()\n",
    "        hijri_year_end = convert.Gregorian(year, 12, 30).to_hijri()\n",
    "\n",
    "        for day in range(1, 30):  # Assuming Ramadan lasts for 29 or 30 days\n",
    "            # Find the date of Ramadan in the Hijri calendar\n",
    "            ramadan_date = convert.Hijri(hijri_year_start.year, 9, day).to_gregorian()\n",
    "\n",
    "            # Append the date to the list\n",
    "            ramadan_dates.append(ramadan_date)\n",
    "\n",
    "    # Create a DataFrame with a column named 'ramadan_dates'\n",
    "    ramadan_df = pd.DataFrame({'ds': ramadan_dates})\n",
    "    return ramadan_df\n",
    "\n",
    "start_year = start_date.year\n",
    "end_year = end_date.year\n",
    "ramadan_df = generate_ramadan_dates_df(start_year, end_year)\n",
    "\n",
    "#### Adding  Ramadan dates in prophet Training Data\n",
    "if ramadan_add_seasonality:\n",
    "    data['is_ramadan'] = data['ds'].isin(ramadan_df['ds']).astype(int)\n",
    "    data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d0a71",
   "metadata": {},
   "source": [
    "## Generate the Weekend Days Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81543c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weekends(start_date, end_date, weekend_days):\n",
    "    '''\n",
    "    This function will generate weekends dataframe with ds and holiday columns\n",
    "    Parameters : \n",
    "    start_date : start date of the data of type datetime\n",
    "    end_date : end date of the data of type datetime\n",
    "    weekend_days : list of weekend days ex: [4] for Friday\n",
    "    return : weekends dataframe with ds and holiday columns\n",
    "    '''\n",
    "    weekends = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        # Check if the current date is a weekend\n",
    "        if current_date.weekday() in weekend_days:\n",
    "            weekends.append(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Create a DataFrame with day names and dates\n",
    "    weekend_df = {'ds': weekends,\n",
    "                  'holiday': [day.strftime('%A') for day in weekends]}\n",
    "\n",
    "    df_weekends = pd.DataFrame(weekend_df)\n",
    "    return df_weekends\n",
    "#print(type(start_date))\n",
    "df_weekends = generate_weekends(start_date, end_date, weekend_days)\n",
    "if Weekend_add_seasonality:\n",
    "    data['is_weekend'] = data['ds'].isin(df_weekends['ds']).astype(int)  \n",
    "if WorkingDays_add_seasonality:\n",
    "    data['is_weekday'] = (data['is_weekend'] == 0).astype(int)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Weekend_add_seasonality:\n",
    "    weekendDaysCount= len(weekend_days)\n",
    "    workingDaysCount= 7 - weekendDaysCount\n",
    "\n",
    "    first_30Days['is_weekend'] = first_30Days['ds'].isin(df_weekends['ds']).astype(int)\n",
    "    onlyWeekends= first_30Days[data['is_weekend']==1]\n",
    "\n",
    "    plt.plot(first_30Days['ds'],first_30Days['y'])\n",
    "    plt.scatter(onlyWeekends['ds'],onlyWeekends['y'], marker='v', color='r')\n",
    "    #increase the width of the plot\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15, 5)\n",
    "if ramadan_add_seasonality:\n",
    "    data['is_ramadan'] = data['ds'].isin(ramadan_df['ds']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0e62",
   "metadata": {},
   "source": [
    "# Outlier\n",
    "##### Original Data Filtered by the Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05213ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if detectoutliers:\n",
    "    #plot like a fot not as a line for data['ds'], data['y']  ds on x axis and y on y axis, dont join the line only the points\n",
    "    plt.scatter(data['ds'], data['y'], linestyle = 'solid',color='red')\n",
    "    #increase the width of the plot\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15, 5)\n",
    "\n",
    "    print(data['y'].describe())\n",
    "    Q1 = data['y'].quantile(0.25)\n",
    "    Q3 = data['y'].quantile(0.75)\n",
    "    QCustom99= data['y'].quantile(0.99)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - IQRRange * IQR\n",
    "    upper_bound = Q3 + IQRRange * IQR\n",
    "    soutliers = data[((data['y'] < lower_bound) | (data['y'] > upper_bound))]\n",
    "\n",
    "    # Identifying outliers\n",
    "    outliers = data[((data['y'] < lower_bound) | (data['y'] > upper_bound))]\n",
    "\n",
    "    # Replace outlier values with the mean\n",
    "    data.loc[outliers.index, 'y'] = data['y'].mean()\n",
    "\n",
    "\n",
    "    plt.scatter(data['ds'], data['y'], linestyle = 'solid',color='green')\n",
    "    #plt.scatter(data['ds'], data['y'], linestyle = 'solid',color='red')\n",
    "\n",
    "\n",
    "    print('CustomQuartile99 < 99% : ' + str(QCustom99))\n",
    "    print('IQR : ' + str(IQR))\n",
    "\n",
    "    print('Number of Outliers :' + str(len(soutliers)))\n",
    "    print('Number of rows in data : ' + str(len(data)))\n",
    "    print('lower_bound : ' + str(lower_bound))\n",
    "    print('upper_bound : ' + str(upper_bound))\n",
    "    print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233f6a3",
   "metadata": {},
   "source": [
    "# Create a Prophet model with flexible parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d54f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralprophet_params = {\n",
    "'growth':growth,\n",
    "#'changepoints':changepoints,\n",
    "'n_changepoints':n_changepoints,\n",
    "'changepoints_range':changepoints_range,\n",
    "\n",
    "'yearly_seasonality':yearly_seasonality,\n",
    "'weekly_seasonality':weekly_seasonality,\n",
    "'daily_seasonality':daily_seasonality,\n",
    "\n",
    "'seasonality_mode':seasonality_mode,\n",
    "'seasonality_reg':seasonality_reg,\n",
    "\n",
    "'quantiles':quantiles,\n",
    "\n",
    "'impute_missing':impute_missing,\n",
    "'impute_linear':impute_linear,\n",
    "'impute_rolling':impute_rolling,\n",
    "'drop_missing':drop_missing,\n",
    "'normalize':normalize,\n",
    "\n",
    "'n_lags':n_lags,\n",
    "'n_forecasts':n_forecasts,\n",
    "\n",
    "'ar_layers':ar_layers,\n",
    "'ar_reg':ar_reg,\n",
    "'lagged_reg_layers':lagged_reg_layers,\n",
    "'learning_rate':learning_rate,\n",
    "\n",
    "'epochs':epochs,\n",
    "'batch_size':batch_size,\n",
    "'loss_func':loss_func,\n",
    "'optimizer':optimizer,\n",
    "\n",
    "'season_global_local':season_global_local,\n",
    "\n",
    "'trend_reg':trend_reg,\n",
    "'trend_reg_threshold':trend_reg_threshold,\n",
    "'trend_global_local':trend_global_local,\n",
    "\n",
    "'newer_samples_weight':newer_samples_weight,\n",
    "'newer_samples_start':newer_samples_start,\n",
    "\n",
    "'collect_metrics':collect_metrics,\n",
    "\n",
    "'global_normalization':global_normalization,\n",
    "'global_time_normalization':global_time_normalization,\n",
    "'unknown_data_normalization':unknown_data_normalization,\n",
    "\n",
    "'accelerator':accelerator,\n",
    "'trainer_config':trainer_config,\n",
    "'prediction_frequency':prediction_frequency\n",
    "\n",
    "}\n",
    "print(neuralprophet_params)\n",
    "# Remove parameters with value None\n",
    "neuralprophet_params = {key: value for key, value in neuralprophet_params.items() if value is not None}\n",
    "print(neuralprophet_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18da56",
   "metadata": {},
   "source": [
    "# **Training Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d797c",
   "metadata": {},
   "source": [
    "#### ****Initialize the Model**** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neuralprophet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralProphet (**neuralprophet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb73b6",
   "metadata": {},
   "source": [
    "### ****Custom  Seasonalties****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom seasonality\n",
    "#if the  passed condition is True or Not none then it  execute the below code\n",
    "#Check the names of the variables from the variables\n",
    "\n",
    "if country_name:\n",
    "    model.add_country_holidays(country_name=country_name)\n",
    "\n",
    "if yearly_add_seasonality:\n",
    "    model.add_seasonality(name='yearly_season' ,period=yearly_season_period ,fourier_order=yearly_season_fourier_order )\n",
    "\n",
    "if quarterly_add_seasonality:\n",
    "    model.add_seasonality(name='quarterly_season' ,period=quarterly_season_period ,fourier_order=quarterly_season_fourier_order )\n",
    "\n",
    "if monthly_add_seasonality:\n",
    "    model.add_seasonality(name='monthly_season' ,period=monthly_season_period ,fourier_order=monthly_season_fourier_order )\n",
    "\n",
    "if Weekend_add_seasonality:\n",
    "    model.add_seasonality(name='Weekends_season' ,period=weekendDaysCount ,fourier_order=Weekends_fourier_order ,condition_name=\"is_weekend\")\n",
    "\n",
    "if WorkingDays_add_seasonality:\n",
    "    model.add_seasonality(name='WorkingDays_season' ,period=workingDaysCount ,fourier_order=WorkingDays_fourier_order ,condition_name=\"is_weekday\")\n",
    "\n",
    "if ramadan_add_seasonality:\n",
    "    model.add_seasonality(name='ramadan_season' ,period=ramadan_period ,fourier_order=ramadan_fourier_order ,condition_name=\"is_ramadan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409559bb",
   "metadata": {},
   "source": [
    "#### ****Fit the model to the data**** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63920a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use static plotly in notebooks\n",
    "model.set_plotting_backend(\"plotly-static\")\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb4ad0",
   "metadata": {},
   "source": [
    "## Generate future Dataframe Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe reaching 365 into the future for our forecast, n_historic_predictions also shows historic data\n",
    "df_future = model.make_future_dataframe(data, n_historic_predictions=True, periods=30)\n",
    " # Predict the future\n",
    "forecast = model.predict(df_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the forecast\n",
    "model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3913ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc52e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.highlight_nth_step_ahead_of_each_forecast(1).plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51433d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 30 days of the forecast\n",
    "forecast.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771729a1",
   "metadata": {},
   "source": [
    "### Comparision of actual data and forecasted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f089bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualdata = pd.read_csv('/home/ajaz/DemandForecasting/Data/actualdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualdata = actualdata.rename(columns={'TransactionDate': 'ds', 'GroupCostPrice': 'actual'})\n",
    "#Convert a dataframe column to date only\n",
    "actualdata['ds']=pd.to_datetime(actualdata['ds']) \n",
    "forecast = forecast[['ds','yhat1']].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(forecast['ds'], forecast['yhat1'], label='forecast')\n",
    "ax.plot(actualdata['ds'], actualdata['actual'], label='actual')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf6f28",
   "metadata": {},
   "source": [
    "## Validation and Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9185c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df_train, df_test = model.split_df(df=df, freq=\"D\", valid_p=0.2)\n",
    "# Split the dataset into training and validation sets\n",
    "forecast_test = model.predict(df=df_test)\n",
    "metrics_test = model.test(df=df_test)\n",
    "metrics_test[['MAE_val']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
