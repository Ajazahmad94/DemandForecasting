{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edfa77f",
   "metadata": {},
   "source": [
    "# **Neural Prophet Parameters**\n",
    "### ******Input Parameters from Interface******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. We have two files (Sampledata.csv and actualData.csv)  I want to merge these two and have only one input file\n",
    "# Split the data into training and testing data\n",
    "# 2. Add a parameters prediction_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf90fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NeuralProphet\n",
    " \n",
    "#1. **Growth Parameters:**\n",
    "detectGrowth=True #bool\n",
    "growth='off'  #Literal['off', 'linear', 'discontinuous']\n",
    "\n",
    "#2. **Changepoints Parameters:**\n",
    "detectChangepoints=True #bool\n",
    "changepoints= None #Optional[list]\n",
    "n_changepoints =None    #0, #int\n",
    "changepoints_range=None     #0.8 #float\n",
    "\n",
    "#3. **Seasonality Parameters:**\n",
    "#To Control Seasonality\n",
    "yearly_seasonality= None  #'auto'ss\n",
    "weekly_seasonality= None   #'auto'\n",
    "daily_seasonality = None   #'auto'\n",
    "\n",
    "seasonality_mode='multiplicative' #['additive', 'multiplicative']\n",
    "seasonality_reg= None    #float 0\n",
    "\n",
    "#4. **Confidence Interval Parameters:**\n",
    "confidence_lv = 0.9\n",
    "#quantiles  = None      #[]   #List[float]\n",
    "quantiles = [round(((1 - confidence_lv) / 2), 2), round((confidence_lv + (1 - confidence_lv) / 2), 2)]\n",
    "\n",
    "#5. **Missing Data Handling:**\n",
    "impute_missing= None,     #bool\n",
    "impute_linear = None,    #int\n",
    "impute_rolling= None,  #int\n",
    "drop_missing  = None   #bool\n",
    "\n",
    "#6. **Normalization Parameters:**\n",
    "normalize=None         #'off'     # Literal['auto', 'soft', 'soft1', 'minmax', 'standardize', 'off']\n",
    "\n",
    "#7. **Lags and Forecasts:**\n",
    "n_lags=None        #0    # int 0    \n",
    "n_forecasts=None   #0 #int 1\n",
    "\n",
    "#8. **Autoregression Parameters:**  \n",
    "ar_layers=None     #[]    #Optional[list]   \n",
    "ar_reg= None       #Optional[float]     \n",
    "lagged_reg_layers= None    #[]   #Optional[list]       \n",
    "learning_rate= 0.1   #Optional[float]\n",
    "\n",
    "#9. **Training Parameters:**\n",
    "epochs= None      #Optional[int]\n",
    "batch_size= None   #Optional[int]\n",
    "loss_func=None     #'Huber'\n",
    "optimizer=None     #'AdamW'\n",
    "\n",
    "#10. **Global/Local Parameters:**\n",
    "season_global_local=None #['global', 'local']\n",
    "trend_global_local= None   #str 'global', 'local'\n",
    "\n",
    "#11. **Trend Parameters:**\n",
    "trend_reg= None  #Optional[float]\n",
    "trend_reg_threshold =None  #Optional[Union[bool, float]]\n",
    "newer_samples_weight= None  # float\n",
    "newer_samples_start =None   #float\n",
    "\n",
    "#12. **Additional Configuration:**\n",
    "collect_metrics= None      #Union [bool, list, dict]\n",
    "\n",
    "global_normalization=None\n",
    "global_time_normalization=None\n",
    "unknown_data_normalization=None\n",
    "\n",
    "accelerator=None  #Optional[str] None\n",
    "trainer_config=None # dict {},\n",
    "prediction_frequency=None  # Optional[dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional  Seasonality regressors\n",
    "\n",
    "#Custom holidays\n",
    "country_name= 'SA'   #   'SA' # Country Code  (ISO 3166-2) for holidayss\n",
    "\n",
    "yearly_add_seasonality=True\n",
    "yearly_season_period=365.25\n",
    "yearly_season_fourier_order=2\n",
    "\n",
    "quarterly_add_seasonality=False\n",
    "quarterly_season_period=None\n",
    "quarterly_season_fourier_order=None\n",
    "\n",
    "monthly_add_seasonality=False\n",
    "monthly_season_period=None\n",
    "monthly_season_fourier_order=None\n",
    "\n",
    "# Weekend days (0-6, Mon-Sun)\n",
    "weekend_days = [4]  # 4 is Friday\n",
    "\n",
    "Weekend_add_seasonality=False\n",
    "weekendDaysCount=1\n",
    "Weekends_fourier_order=5\n",
    "\n",
    "WorkingDays_add_seasonality=False\n",
    "workingDaysCount=6\n",
    "WorkingDays_fourier_order=5\n",
    "\n",
    "ramadan_add_seasonality=False\n",
    "ramadan_period=29.33\n",
    "ramadan_fourier_order=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc4e0f",
   "metadata": {},
   "source": [
    "#### ******Parameters used in other calc, other than the model******\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty sensitivity for PELT algorithm: 'High', 'Medium', 'Low' : Used to determine the penalty value for the PELT algo which is used for changepoint detection\n",
    "PenaltySensitivity =\"High\"  \n",
    "\n",
    "# Model type for changepoint detection: 'l1' (linear 1), 'l2' (linear 2), 'rbf' (radial basis function)\n",
    "pltModelType = \"l2\"  # \"l2\", \"rbf\"\n",
    "\n",
    "detectOutliers =False # If True, outliers are detected and removed from the data else outliers are not detected and not removed from the data\n",
    "\n",
    "#IQR stands for Interquartile Range, which is a measure of statistical dispersion of data\n",
    "#IQR Range for outlier detection (1.5 is default) 3 is too high ,  upper_bound = Q3 + IQRRange * IQR and lower_bound = Q1 - IQRRange * IQR \n",
    "\n",
    "IQRRange=1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5bf95",
   "metadata": {},
   "source": [
    "# ****Prophet Algorithm****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c065b3",
   "metadata": {},
   "source": [
    "### ****Importing Libraries****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0c3a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Utitlies package\n"
     ]
    }
   ],
   "source": [
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import ruptures as rpt\n",
    "import warnings\n",
    "import holidays\n",
    "from hijri_converter import convert\n",
    "from datetime import date,datetime, timedelta\n",
    "from prophet.diagnostics import performance_metrics, cross_validation\n",
    "\n",
    "\n",
    "from Utitlies.fileIO import loadCsvExcelFile\n",
    "\n",
    "from Utitlies.dataAnalysis import detectGrowth \n",
    "\n",
    "from Utitlies.dataAnalysis import detectChangepoints\n",
    "from Utitlies.dataAnalysis import detectOutliers\n",
    "from Utitlies.dateGeneration import generateRamadanDates\n",
    "from Utitlies.dateGeneration import generateWeekends\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d078d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utitlies.fileIO import loadCsvExcelFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33839ac",
   "metadata": {},
   "source": [
    "### ****Importing the dataset****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c07e6a",
   "metadata": {},
   "source": [
    "##### Importing Data using the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73537195",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_days=30\n",
    "\n",
    "#Excel file Path\n",
    "file_path= '/home/ajaz/DemandForecasting/Data/data.csv'  \n",
    "\n",
    "\n",
    "def split_data(data, prediction_days):\n",
    "    \"\"\"\n",
    "    Splits the given data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    - data: The input data to be split.\n",
    "    - prediction_days: The number of days to be used for testing.\n",
    "\n",
    "    Returns:\n",
    "    - train_data: The training data containing all but the last `prediction_days` rows.\n",
    "    - test_data: The testing data containing the last `prediction_days` rows.\n",
    "    \"\"\"\n",
    "    return data.iloc[:-prediction_days], data.iloc[-prediction_days:]\n",
    "\n",
    "trainData , testData = split_data(loadCsvExcelFile(file_path), prediction_days)\n",
    "\n",
    "\n",
    "#Load Data \n",
    "#data = loadCsvExcelFile(file_path)\n",
    "\n",
    "\n",
    "trainData['date'] = pd.to_datetime(trainData['date'])\n",
    "trainData.rename(columns={'date':'ds','value':'y'},inplace=True)\n",
    "# Get the first and last dates of the filtered data\n",
    "startDate = pd.to_datetime( trainData['ds'].iloc[0])\n",
    "endDate = pd.to_datetime( trainData['ds'].iloc[-1])\n",
    "\n",
    "startYear = startDate.year\n",
    "endYear = endDate.year\n",
    "\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f01bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Growth Detection\n",
    "if detectGrowth:\n",
    "    growth = detectGrowth(trainData)\n",
    "    print(\"Growth Detected : \",growth)\n",
    "else:\n",
    "    print(\"Manual, Growth Detection is Off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b04a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect Change points\n",
    "if detectChangepoints:\n",
    "    changepoints= detectChangepoints(trainData, pltModelType, PenaltySensitivity)\n",
    "    print(\"Sucessfully detected Change points\")\n",
    "    #print(\"Change points : \",changepoints)\n",
    "else:\n",
    "    print(\"Manual, Change points Detection is Off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect Outliers\n",
    "if detectOutliers:\n",
    "    lower_bound, upper_bound = detectOutliers(trainData, IQRRange)\n",
    "    outliers = trainData[((trainData['y'] < lower_bound) | (trainData['y'] > upper_bound))]\n",
    "    trainData.loc[outliers.index, 'y'] = trainData['y'].mean()\n",
    "    print(\"Sucessfully Removed the Outliers\")\n",
    "print(\"Outlier Detection  is disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602687f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Ramadan Seasonality\n",
    "\n",
    "if ramadan_add_seasonality:\n",
    "    ramadan_df = generateRamadanDates(startYear, endYear)\n",
    "    trainData['is_ramadan'] = trainData['ds'].isin(ramadan_df['ds']).astype(int)\n",
    "    print(\"Sucessfully Added Ramadan dates in prophet Training Data\")\n",
    "    print(trainData)\n",
    "else:\n",
    "    print(\"Ramadan Seasonality is disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables for Weekend and Working days must be imported from input parameters\n",
    "startDate = '2018-01-01'\n",
    "endDate = '2023-07-31'\n",
    "weekendDays = [4]  # 4 is Friday\n",
    "\n",
    "if Weekend_add_seasonality:\n",
    "    df_weekends = generateWeekends(startDate, endDate, *weekendDays)\n",
    "    trainData['is_weekend'] = trainData['ds'].isin(df_weekends['ds']).astype(int)  \n",
    "    print(\"Sucessfully Added Weekend dates in prophet Training Data\")\n",
    "else:\n",
    "    print(\"Weekend Seasonality is disabled\")\n",
    "\n",
    "if WorkingDays_add_seasonality:\n",
    "    trainData['is_weekday'] = (trainData['is_weekend'] == 0).astype(int)\n",
    "    print(\"Sucessfully Added Working days in prophet Training Data\")\n",
    "else:\n",
    "    print(\"Working days Seasonality is disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233f6a3",
   "metadata": {},
   "source": [
    "# Create a Prophet model with flexible parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d54f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralprophet_params = {\n",
    "'growth':growth,\n",
    "'changepoints':changepoints,\n",
    "'n_changepoints':n_changepoints,\n",
    "'changepoints_range':changepoints_range,\n",
    "\n",
    "'yearly_seasonality':yearly_seasonality,\n",
    "'weekly_seasonality':weekly_seasonality,\n",
    "'daily_seasonality':daily_seasonality,\n",
    "\n",
    "'seasonality_mode':seasonality_mode,\n",
    "'seasonality_reg':seasonality_reg,\n",
    "\n",
    "'quantiles':quantiles,\n",
    "\n",
    "'impute_missing':impute_missing,\n",
    "'impute_linear':impute_linear,\n",
    "'impute_rolling':impute_rolling,\n",
    "'drop_missing':drop_missing,\n",
    "'normalize':normalize,\n",
    "\n",
    "'n_lags':n_lags,\n",
    "'n_forecasts':n_forecasts,\n",
    "\n",
    "'ar_layers':ar_layers,\n",
    "'ar_reg':ar_reg,\n",
    "'lagged_reg_layers':lagged_reg_layers,\n",
    "'learning_rate':learning_rate,\n",
    "\n",
    "'epochs':epochs,\n",
    "'batch_size':batch_size,\n",
    "'loss_func':loss_func,\n",
    "'optimizer':optimizer,\n",
    "\n",
    "'season_global_local':season_global_local,\n",
    "\n",
    "'trend_reg':trend_reg,\n",
    "'trend_reg_threshold':trend_reg_threshold,\n",
    "'trend_global_local':trend_global_local,\n",
    "\n",
    "'newer_samples_weight':newer_samples_weight,\n",
    "'newer_samples_start':newer_samples_start,\n",
    "\n",
    "'collect_metrics':collect_metrics,\n",
    "\n",
    "'global_normalization':global_normalization,\n",
    "'global_time_normalization':global_time_normalization,\n",
    "'unknown_data_normalization':unknown_data_normalization,\n",
    "\n",
    "'accelerator':accelerator,\n",
    "'trainer_config':trainer_config,\n",
    "'prediction_frequency':prediction_frequency\n",
    "\n",
    "}\n",
    "print(neuralprophet_params)\n",
    "# Remove parameters with value None\n",
    "neuralprophet_params = {key: value for key, value in neuralprophet_params.items() if value is not None}\n",
    "print(neuralprophet_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18da56",
   "metadata": {},
   "source": [
    "# **Training Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d797c",
   "metadata": {},
   "source": [
    "#### ****Initialize the Model**** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neuralprophet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralProphet (**neuralprophet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb73b6",
   "metadata": {},
   "source": [
    "### ****Custom  Seasonalties****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom seasonality\n",
    "#if the  passed condition is True or Not none then it  execute the below code\n",
    "#Check the names of the variables from the variables\n",
    "\n",
    "if country_name:\n",
    "    model.add_country_holidays(country_name=country_name)\n",
    "\n",
    "if yearly_add_seasonality:\n",
    "    model.add_seasonality(name='yearly_season' ,period=yearly_season_period ,fourier_order=yearly_season_fourier_order )\n",
    "\n",
    "if quarterly_add_seasonality:\n",
    "    model.add_seasonality(name='quarterly_season' ,period=quarterly_season_period ,fourier_order=quarterly_season_fourier_order )\n",
    "\n",
    "if monthly_add_seasonality:\n",
    "    model.add_seasonality(name='monthly_season' ,period=monthly_season_period ,fourier_order=monthly_season_fourier_order )\n",
    "\n",
    "if Weekend_add_seasonality:\n",
    "    model.add_seasonality(name='Weekends_season' ,period=weekendDaysCount ,fourier_order=Weekends_fourier_order ,condition_name=\"is_weekend\")\n",
    "\n",
    "if WorkingDays_add_seasonality:\n",
    "    model.add_seasonality(name='WorkingDays_season' ,period=workingDaysCount ,fourier_order=WorkingDays_fourier_order ,condition_name=\"is_weekday\")\n",
    "\n",
    "if ramadan_add_seasonality:\n",
    "    model.add_seasonality(name='ramadan_season' ,period=ramadan_period ,fourier_order=ramadan_fourier_order ,condition_name=\"is_ramadan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409559bb",
   "metadata": {},
   "source": [
    "#### ****Fit the model to the data**** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63920a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use static plotly in notebooks\n",
    "model.set_plotting_backend(\"plotly-static\")\n",
    "model.fit(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb4ad0",
   "metadata": {},
   "source": [
    "## Generate future Dataframe Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe reaching 365 into the future for our forecast, n_historic_predictions also shows historic data\n",
    "df_future = model.make_future_dataframe(trainData, n_historic_predictions=True, periods=30)\n",
    " # Predict the future\n",
    "forecast = model.predict(df_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the forecast\n",
    "model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3913ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc52e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.highlight_nth_step_ahead_of_each_forecast(1).plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51433d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 30 days of the forecast\n",
    "forecast.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771729a1",
   "metadata": {},
   "source": [
    "### Comparision of actual data and forecasted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f089bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testData = pd.read_csv('/home/ajaz/DemandForecasting/Data/actualdata.csv')\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testData.rename(columns={'date': 'ds', 'GroupCostPrice': 'actual'})\n",
    "#Convert a dataframe column to date only\n",
    "testData['ds']=pd.to_datetime(testData['ds']) \n",
    "forecast = forecast[['ds','yhat1']].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the data \n",
    "\n",
    "# Assuming 'actualdata' and 'forecast' are already defined and preprocessed as per your snippet\n",
    "\n",
    "# Step 2: Filter 'actualdata' to only include dates that are in 'forecast'\n",
    "filtered_actualdata = testData[testData['ds'].isin(forecast['ds'])]\n",
    "\n",
    "# Step 3: Merge 'filtered_actualdata' and 'forecast' on the 'ds' column\n",
    "combined_df = pd.merge(filtered_actualdata, forecast, on='ds', how='inner')\n",
    "\n",
    "# Rename columns for clarity\n",
    "combined_df.rename(columns={'yhat1': 'forecast', 'y': 'actual'}, inplace=True)\n",
    "\n",
    "# Now 'combined_df' contains the date ('ds'), the actual values, and the forecasted values ('forecast')\n",
    "\n",
    "# Export to CSV\n",
    "\n",
    "combined_df.to_csv('/home/ajaz/DemandForecasting/Data/Output/NeuralProphetforecast.csv', index=False)\n",
    "\n",
    "\n",
    "# Export to Excel\n",
    "#combined_df.to_excel('/home/ajaz/DemandForecasting/Data/forecast_vs_actual.xlsx', index=False, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(forecast['ds'], forecast['yhat1'], label='forecast')\n",
    "ax.plot(testData['ds'], testData['value'], label='actual')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf6f28",
   "metadata": {},
   "source": [
    "## Validation and Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9185c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainData.copy()\n",
    "df_train, df_test = model.split_df(df=df, freq=\"D\", valid_p=0.2)\n",
    "# Split the dataset into training and validation sets\n",
    "forecast_test = model.predict(df=df_test)\n",
    "metrics_test = model.test(df=df_test)\n",
    "metrics_test[['MAE_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd63934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c08f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
